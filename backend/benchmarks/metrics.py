"""Utility functions for computing transcription metrics.

These functions implement a minimal set of metrics suitable for
synthetic audio benchmarks.  They are intentionally lightweight and
require only NumPy; additional metrics from mir_eval or sound
libraries can be integrated later if desired.

Metric definitions
------------------

Pitch metrics:
    - ``cents_error``: mean absolute error in cents on voiced frames.
    - ``voicing_precision`` and ``voicing_recall``: proportion of
      correctly voiced/unvoiced detections.

Note metrics:
    - ``note_f1``: harmonic mean of precision and recall for
      correctly detected notes (by pitch and onset within tolerance).
    - ``onset_mae`` and ``offset_mae``: mean absolute error on start
      and end times of notes.

These metrics operate on simple Python lists or NumPy arrays; they
do not depend on the music21 library and thus can be used in any
environment.
"""

from __future__ import annotations

from typing import List, Tuple
import numpy as np


def cents_error(pred_hz: np.ndarray, gt_hz: np.ndarray) -> float:
    """Compute the mean absolute cents error on voiced frames.

    Parameters
    ----------
    pred_hz : np.ndarray
        Predicted fundamental frequency per frame (Hz).
    gt_hz : np.ndarray
        Ground‑truth fundamental frequency per frame (Hz).

    Returns
    -------
    float
        Mean absolute error in cents.  Returns ``nan`` if no voiced
        frames are present in either prediction or ground truth.
    """
    pred_hz = np.asarray(pred_hz, dtype=np.float64).reshape(-1)
    gt_hz = np.asarray(gt_hz, dtype=np.float64).reshape(-1)
    n = min(len(pred_hz), len(gt_hz))
    if n == 0:
        return float('nan')
    pred_hz = pred_hz[:n]
    gt_hz = gt_hz[:n]
    voiced = (gt_hz > 0.0)
    if not np.any(voiced):
        return float('nan')
    pred_voiced = np.where(pred_hz > 0.0, pred_hz, np.nan)
    err_cents = 1200.0 * np.log2(np.maximum(pred_voiced, 1e-9) / np.maximum(gt_hz, 1e-9))
    return float(np.nanmean(np.abs(err_cents[voiced])))


def voicing_precision_recall(pred_hz: np.ndarray, gt_hz: np.ndarray) -> Tuple[float, float]:
    """Compute voicing precision and recall.

    Parameters
    ----------
    pred_hz : np.ndarray
        Predicted fundamental frequency per frame (Hz).
    gt_hz : np.ndarray
        Ground‑truth fundamental frequency per frame (Hz).

    Returns
    -------
    (float, float)
        (precision, recall) of voiced frame detection.  Precision is
        the fraction of predicted voiced frames that are actually
        voiced; recall is the fraction of ground‑truth voiced frames
        that are correctly predicted as voiced.  If there are no
        voiced frames in ground truth, both precision and recall are
        returned as ``nan``.
    """
    pred_hz = np.asarray(pred_hz, dtype=np.float64).reshape(-1)
    gt_hz = np.asarray(gt_hz, dtype=np.float64).reshape(-1)
    n = min(len(pred_hz), len(gt_hz))
    if n == 0:
        return float('nan'), float('nan')
    pred_voiced = pred_hz[:n] > 0.0
    gt_voiced = gt_hz[:n] > 0.0
    tp = np.sum(pred_voiced & gt_voiced)
    fp = np.sum(pred_voiced & ~gt_voiced)
    fn = np.sum(~pred_voiced & gt_voiced)
    precision = tp / float(tp + fp) if (tp + fp) > 0 else float('nan')
    recall = tp / float(tp + fn) if (tp + fn) > 0 else float('nan')
    return precision, recall


def note_f1(pred_notes: List[Tuple[int, float, float]], gt_notes: List[Tuple[int, float, float]],
            onset_tol: float = 0.05) -> float:
    """Compute note F1 score between predicted and ground‑truth notes.

    Parameters
    ----------
    pred_notes : List[Tuple[int, float, float]]
        Predicted notes as (midi, start_sec, end_sec).
    gt_notes : List[Tuple[int, float, float]]
        Ground‑truth notes as (midi, start_sec, end_sec).
    onset_tol : float, optional
        Onset tolerance in seconds.  If the absolute difference
        between predicted and ground‑truth onsets is within this
        tolerance and the MIDI pitches match, the note is considered
        correct.  Default is 0.05 (50 ms).

    Returns
    -------
    float
        Note F1 score: 2 * (precision * recall) / (precision + recall).
    """
    if not gt_notes and not pred_notes:
        return float('nan')
    used = [False] * len(gt_notes)
    tp = 0
    for p_midi, p_start, p_end in pred_notes:
        for i, (g_midi, g_start, g_end) in enumerate(gt_notes):
            if used[i]:
                continue
            if p_midi == g_midi and abs(p_start - g_start) <= onset_tol:
                tp += 1
                used[i] = True
                break
    fp = len(pred_notes) - tp
    fn = len(gt_notes) - tp
    precision = tp / float(tp + fp) if (tp + fp) > 0 else 0.0
    recall = tp / float(tp + fn) if (tp + fn) > 0 else 0.0
    return (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0


def _dtw_path(pred_onsets: List[float], gt_onsets: List[float]) -> List[Tuple[int, int]]:
    n, m = len(pred_onsets), len(gt_onsets)
    if n == 0 or m == 0:
        return []
    dp = np.full((n + 1, m + 1), np.inf)
    dp[0, 0] = 0.0
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            cost = abs(pred_onsets[i - 1] - gt_onsets[j - 1])
            dp[i, j] = cost + min(dp[i - 1, j], dp[i, j - 1], dp[i - 1, j - 1])

    path: List[Tuple[int, int]] = []
    i, j = n, m
    while i > 0 or j > 0:
        options = []
        if i > 0 and j > 0:
            options.append((dp[i - 1, j - 1], "diag"))
        if i > 0:
            options.append((dp[i - 1, j], "up"))
        if j > 0:
            options.append((dp[i, j - 1], "left"))
        _, move = min(options, key=lambda x: x[0])
        if move == "diag":
            path.append((i - 1, j - 1))
            i -= 1
            j -= 1
        elif move == "up":
            i -= 1
        else:
            j -= 1
    path.reverse()
    return path


def dtw_note_f1(
    pred_notes: List[Tuple[int, float, float]],
    gt_notes: List[Tuple[int, float, float]],
    onset_tol: float = 0.05,
    pitch_mismatch_penalty: float = 0.05,
) -> float:
    """DTW-aligned Note F1 using onset sequences with optional pitch penalty."""

    if not gt_notes and not pred_notes:
        return float('nan')

    pred_sorted = sorted(pred_notes, key=lambda x: x[1])
    gt_sorted = sorted(gt_notes, key=lambda x: x[1])
    path = _dtw_path([p[1] for p in pred_sorted], [g[1] for g in gt_sorted])

    tp = 0
    for i, j in path:
        p_midi, p_start, _ = pred_sorted[i]
        g_midi, g_start, _ = gt_sorted[j]
        onset_close = abs(p_start - g_start) <= onset_tol
        pitch_match = p_midi == g_midi
        # Apply a light penalty for pitch mismatch by requiring tighter onset
        if onset_close and (pitch_match or abs(p_start - g_start) <= max(0.0, onset_tol - pitch_mismatch_penalty)):
            tp += 1

    fp = len(pred_sorted) - tp
    fn = len(gt_sorted) - tp
    precision = tp / float(tp + fp) if (tp + fp) > 0 else 0.0
    recall = tp / float(tp + fn) if (tp + fn) > 0 else 0.0
    return (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0


def dtw_onset_error_ms(
    pred_notes: List[Tuple[int, float, float]],
    gt_notes: List[Tuple[int, float, float]],
) -> float:
    """Mean onset error (ms) along the DTW alignment path for matching MIDI pitches."""

    if not pred_notes or not gt_notes:
        return float('nan')

    pred_sorted = sorted(pred_notes, key=lambda x: x[1])
    gt_sorted = sorted(gt_notes, key=lambda x: x[1])
    path = _dtw_path([p[1] for p in pred_sorted], [g[1] for g in gt_sorted])

    errors = []
    for i, j in path:
        p_midi, p_start, _ = pred_sorted[i]
        g_midi, g_start, _ = gt_sorted[j]
        if p_midi == g_midi:
            errors.append(abs(p_start - g_start) * 1000.0)

    if not errors:
        return float('nan')
    return float(np.mean(errors))


def onset_offset_mae(pred_notes: List[Tuple[int, float, float]], gt_notes: List[Tuple[int, float, float]]) -> Tuple[float, float]:
    """Compute mean absolute error of note onsets and offsets.

    Returns (onset_mae, offset_mae).  If there are no matching notes
    (by MIDI pitch), returns (nan, nan).
    """
    if not gt_notes or not pred_notes:
        return float('nan'), float('nan')
    errors_start = []
    errors_end = []
    for p_midi, p_start, p_end in pred_notes:
        # find closest matching MIDI note in gt
        candidates = [(i, g_start, g_end) for i, (g_midi, g_start, g_end) in enumerate(gt_notes) if g_midi == p_midi]
        if not candidates:
            continue
        # choose candidate with minimal onset error
        i_best, g_start_best, g_end_best = min(candidates, key=lambda x: abs(x[1] - p_start))
        errors_start.append(abs(p_start - g_start_best))
        errors_end.append(abs(p_end - g_end_best))
    if not errors_start:
        return float('nan'), float('nan')
    return float(np.mean(errors_start)), float(np.mean(errors_end))


def compute_symptom_metrics(pred_notes: List[Tuple[int, float, float]]) -> dict[str, float]:
    """Compute diagnostic symptom metrics from predicted notes."""
    if not pred_notes:
        return {
            "fragmentation_score": 0.0,
            "note_count_per_10s": 0.0,
            "median_note_len_ms": 0.0,
            "octave_jump_rate": 0.0,
            "note_count": 0.0
        }

    # Sort by start time
    notes = sorted(pred_notes, key=lambda x: x[1])
    durations = [(end - start) * 1000.0 for _, start, end in notes]
    total_dur_s = max(n[2] for n in notes) - min(n[1] for n in notes) if notes else 0.0

    # Fragmentation: ratio of notes < 80ms
    short_notes = sum(1 for d in durations if d < 80.0)
    fragmentation_score = short_notes / len(notes) if notes else 0.0

    # Density
    note_count_per_10s = (len(notes) / total_dur_s * 10.0) if total_dur_s > 0 else 0.0

    # Median duration
    median_note_len_ms = float(np.median(durations)) if durations else 0.0

    # Octave jumps (intervals > 11 semitones)
    jumps = 0
    if len(notes) > 1:
        for i in range(1, len(notes)):
            prev = notes[i-1]
            curr = notes[i]
            # Only count if consecutive in time (gap < 200ms)
            if (curr[1] - prev[2]) < 0.2:
                interval = abs(curr[0] - prev[0])
                if interval > 11:
                    jumps += 1
    octave_jump_rate = jumps / (len(notes) - 1) if len(notes) > 1 else 0.0

    return {
        "fragmentation_score": fragmentation_score,
        "note_count_per_10s": note_count_per_10s,
        "median_note_len_ms": median_note_len_ms,
        "octave_jump_rate": octave_jump_rate,
        "note_count": float(len(notes))
    }